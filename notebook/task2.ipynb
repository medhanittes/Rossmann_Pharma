{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the DataFrame:\n",
      "Index(['Store', 'StoreType', 'Assortment', 'CompetitionDistance',\n",
      "       'CompetitionOpenSinceMonth', 'CompetitionOpenSinceYear', 'Promo2',\n",
      "       'Promo2SinceWeek', 'Promo2SinceYear', 'PromoInterval'],\n",
      "      dtype='object')\n",
      "Columns in the DataFrame:\n",
      "Index(['Store', 'DayOfWeek', 'Date', 'Sales', 'Customers', 'Open', 'Promo',\n",
      "       'StateHoliday', 'SchoolHoliday'],\n",
      "      dtype='object')\n",
      "First few rows of the DataFrame:\n",
      "   Store StoreType Assortment  CompetitionDistance  CompetitionOpenSinceMonth  \\\n",
      "0      1         c          a               1270.0                        9.0   \n",
      "1      2         a          a                570.0                       11.0   \n",
      "2      3         a          a              14130.0                       12.0   \n",
      "3      4         c          c                620.0                        9.0   \n",
      "4      5         a          a              29910.0                        4.0   \n",
      "\n",
      "   CompetitionOpenSinceYear  Promo2  Promo2SinceWeek  Promo2SinceYear  \\\n",
      "0                    2008.0       0              NaN              NaN   \n",
      "1                    2007.0       1             13.0           2010.0   \n",
      "2                    2006.0       1             14.0           2011.0   \n",
      "3                    2009.0       0              NaN              NaN   \n",
      "4                    2015.0       0              NaN              NaN   \n",
      "\n",
      "     PromoInterval  \n",
      "0              NaN  \n",
      "1  Jan,Apr,Jul,Oct  \n",
      "2  Jan,Apr,Jul,Oct  \n",
      "3              NaN  \n",
      "4              NaN  \n",
      "First few rows of the DataFrame:\n",
      "   Store  DayOfWeek        Date  Sales  Customers  Open  Promo StateHoliday  \\\n",
      "0      1          5  2015-07-31   5263        555     1      1   No Holiday   \n",
      "1      2          5  2015-07-31   6064        625     1      1   No Holiday   \n",
      "2      3          5  2015-07-31   8314        821     1      1   No Holiday   \n",
      "3      4          5  2015-07-31  13995       1498     1      1   No Holiday   \n",
      "4      5          5  2015-07-31   4822        559     1      1   No Holiday   \n",
      "\n",
      "   SchoolHoliday  \n",
      "0              1  \n",
      "1              1  \n",
      "2              1  \n",
      "3              1  \n",
      "4              1  \n",
      "Updated DataFrame with CompetitionOpenSince:\n",
      "   Store StoreType Assortment  CompetitionDistance  CompetitionOpenSinceMonth  \\\n",
      "0      1         c          a               1270.0                        9.0   \n",
      "1      2         a          a                570.0                       11.0   \n",
      "2      3         a          a              14130.0                       12.0   \n",
      "3      4         c          c                620.0                        9.0   \n",
      "4      5         a          a              29910.0                        4.0   \n",
      "\n",
      "   CompetitionOpenSinceYear  Promo2  Promo2SinceWeek  Promo2SinceYear  \\\n",
      "0                    2008.0       0              NaN              NaN   \n",
      "1                    2007.0       1             13.0           2010.0   \n",
      "2                    2006.0       1             14.0           2011.0   \n",
      "3                    2009.0       0              NaN              NaN   \n",
      "4                    2015.0       0              NaN              NaN   \n",
      "\n",
      "     PromoInterval CompetitionOpenSince  \n",
      "0              NaN           2008-09-01  \n",
      "1  Jan,Apr,Jul,Oct           2007-11-01  \n",
      "2  Jan,Apr,Jul,Oct           2006-12-01  \n",
      "3              NaN           2009-09-01  \n",
      "4              NaN           2015-04-01  \n",
      "Updated DataFrame:\n",
      "      Store StoreType Assortment  CompetitionDistance  \\\n",
      "0 -1.730498         c          a            -0.538290   \n",
      "1 -1.727391         a          a            -0.629739   \n",
      "2 -1.724284         a          a             1.141759   \n",
      "3 -1.721178         c          c            -0.623207   \n",
      "4 -1.718071         a          a             3.203281   \n",
      "\n",
      "   CompetitionOpenSinceMonth  CompetitionOpenSinceYear    Promo2  \\\n",
      "0                   0.955066                  0.319763 -1.024516   \n",
      "1                   1.464221                  0.166282  0.976071   \n",
      "2                   1.718799                  0.012802  0.976071   \n",
      "3                   0.955066                  0.473244 -1.024516   \n",
      "4                  -0.317823                  1.394130 -1.024516   \n",
      "\n",
      "   Promo2SinceWeek  Promo2SinceYear    PromoInterval CompetitionOpenSince  \\\n",
      "0        -0.777805        -1.024515                0           2008-09-01   \n",
      "1         0.059001         0.974317  Jan,Apr,Jul,Oct           2007-11-01   \n",
      "2         0.123370         0.975311  Jan,Apr,Jul,Oct           2006-12-01   \n",
      "3        -0.777805        -1.024515                0           2009-09-01   \n",
      "4        -0.777805        -1.024515                0           2015-04-01   \n",
      "\n",
      "        date holiday_date  weekday  weekend  days_to_holiday  \\\n",
      "0 2023-09-23   2023-12-25        5      0.0              0.0   \n",
      "1 2023-09-23   2023-12-25        5      0.0              0.0   \n",
      "2 2023-09-23   2023-12-25        5      0.0              0.0   \n",
      "3 2023-09-23   2023-12-25        5      0.0              0.0   \n",
      "4 2023-09-23   2023-12-25        5      0.0              0.0   \n",
      "\n",
      "   days_after_holiday  beginning_of_month  mid_month  end_of_month  \n",
      "0                 0.0               False      False          True  \n",
      "1                 0.0               False      False          True  \n",
      "2                 0.0               False      False          True  \n",
      "3                 0.0               False      False          True  \n",
      "4                 0.0               False      False          True  \n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv(r'D:\\Week4\\data\\store.csv')\n",
    "df = pd.read_csv(r'D:\\Week4\\data\\train.csv')\n",
    "\n",
    "# Check the columns of the DataFrame\n",
    "print(\"Columns in the DataFrame:\")\n",
    "print(data.columns)\n",
    "print(\"Columns in the DataFrame:\")\n",
    "print(df.columns)\n",
    "\n",
    "# Inspect the first few rows of the DataFrame\n",
    "print(\"First few rows of the DataFrame:\")\n",
    "print(data.head())\n",
    "print(\"First few rows of the DataFrame:\")\n",
    "print(df.head())\n",
    "# Handle missing values in CompetitionOpenSinceMonth and CompetitionOpenSinceYear\n",
    "data['CompetitionOpenSinceMonth'] = data['CompetitionOpenSinceMonth'].fillna(1)  # Default to January if NaN\n",
    "data['CompetitionOpenSinceYear'] = data['CompetitionOpenSinceYear'].fillna(2000)  # Default to year 2000 if NaN\n",
    "\n",
    "# Create a new date column from CompetitionOpenSinceMonth and CompetitionOpenSinceYear\n",
    "data['CompetitionOpenSince'] = pd.to_datetime(\n",
    "    data['CompetitionOpenSinceMonth'].astype(int).astype(str) + '-' +\n",
    "    data['CompetitionOpenSinceYear'].astype(int).astype(str),\n",
    "    format='%m-%Y',\n",
    "    errors='coerce'\n",
    ")\n",
    "\n",
    "# Check the updated DataFrame with CompetitionOpenSince\n",
    "print(\"Updated DataFrame with CompetitionOpenSince:\")\n",
    "print(data.head())\n",
    "\n",
    "# Create a date column for analysis (example: using today's date or a specific date)\n",
    "data['date'] = pd.to_datetime('2023-09-23')  # Replace with your actual date logic\n",
    "\n",
    "# If you have a holiday_date column, ensure it is present\n",
    "data['holiday_date'] = pd.to_datetime('2023-12-25')  # Example holiday date\n",
    "\n",
    "# Create additional date-related features\n",
    "data['weekday'] = data['date'].dt.weekday\n",
    "data['weekend'] = (data['weekday'] >= 5).astype(int)\n",
    "data['days_to_holiday'] = (data['holiday_date'] - data['date']).dt.days\n",
    "data['days_after_holiday'] = (data['date'] - data['holiday_date']).dt.days\n",
    "data['beginning_of_month'] = data['date'].dt.day <= 7\n",
    "data['mid_month'] = (data['date'].dt.day > 7) & (data['date'].dt.day <= 14)\n",
    "data['end_of_month'] = data['date'].dt.day > 14\n",
    "\n",
    "# Fill NaN values\n",
    "data.fillna(0, inplace=True)  # Example of filling NaNs\n",
    "\n",
    "# Standardize numeric features\n",
    "scaler = StandardScaler()\n",
    "numeric_features = data.select_dtypes(include=['float64', 'int64'])\n",
    "data[numeric_features.columns] = scaler.fit_transform(numeric_features)\n",
    "\n",
    "# Check the updated DataFrame\n",
    "print(\"Updated DataFrame:\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Store            0\n",
      "DayOfWeek        0\n",
      "Date             0\n",
      "Sales            0\n",
      "Customers        0\n",
      "Open             0\n",
      "Promo            0\n",
      "StateHoliday     0\n",
      "SchoolHoliday    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Handle missing values if necessary\n",
    "# Fill missing values in 'Customers' and assign it back to the column\n",
    "df['Customers'] = df['Customers'].fillna(0)\n",
    "\n",
    "# Convert 'Date' to datetime format\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Extract additional features\n",
    "df['Year'] = df['Date'].dt.year\n",
    "df['Month'] = df['Date'].dt.month\n",
    "df['Day'] = df['Date'].dt.day\n",
    "df['DayOfWeek'] = df['Date'].dt.dayofweek\n",
    "\n",
    "# Define features and target\n",
    "X = df.drop(['Sales'], axis=1)  # Features\n",
    "y = df['Sales']  # Target\n",
    "\n",
    "# Convert categorical variables to numeric if needed\n",
    "X = pd.get_dummies(X, columns=['Store', 'StateHoliday'], drop_first=True)\n",
    "\n",
    "# Ensure all data is numeric\n",
    "X = X.select_dtypes(exclude=['object'])  # Keep only numeric columns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Train a Random Forest model\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'Mean Squared Error: {mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['sales'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msales\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Features\u001b[39;00m\n\u001b[0;32m      2\u001b[0m y \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msales\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# Target\u001b[39;00m\n\u001b[0;32m      4\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "File \u001b[1;32md:\\Week4\\myvenv\\Lib\\site-packages\\pandas\\core\\frame.py:5581\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[0;32m   5434\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5435\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5442\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   5443\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5444\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5445\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5446\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5579\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5580\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5582\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5583\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5584\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5585\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5587\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5588\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5589\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Week4\\myvenv\\Lib\\site-packages\\pandas\\core\\generic.py:4788\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4786\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4788\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4790\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4791\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32md:\\Week4\\myvenv\\Lib\\site-packages\\pandas\\core\\generic.py:4830\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4828\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4829\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4830\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4831\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4833\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4834\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32md:\\Week4\\myvenv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:7070\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   7068\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   7069\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 7070\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   7071\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   7072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['sales'] not found in axis\""
     ]
    }
   ],
   "source": [
    "\n",
    "X = df.drop(['sales'], axis=1)  # Features\n",
    "y = df['sales']  # Target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('model', RandomForestRegressor())\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
